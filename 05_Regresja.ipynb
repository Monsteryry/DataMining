{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Kopia notatnika 05_Regresja.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zzeFZqUVQz4R",
        "9cBIJNsqQz4R",
        "cFgxWbYuQz4S",
        "wI16kSaRQz4T",
        "6n9sPIesQz4T",
        "ZEYHIVaDQz4U",
        "fMNCfE3oQz4U",
        "9qQXektwQz4U",
        "Zff5ajWVQz4V",
        "HvK1Z_a9Qz4W",
        "TenNexR4Qz4X",
        "BdsPygTuQz4X",
        "lK1-naSIQz4Z",
        "NfpBoqQoQz4b",
        "IE2GWl5sQz4c",
        "aNpHRfNYQz4c",
        "b0rJwnSVQz4d",
        "6uDeppE6Qz4d",
        "tYLnFfDiQz4e",
        "JbGb8W9uQz4f"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4PbSdWKQz4M"
      },
      "source": [
        "# 5. Regresja\n",
        "\n",
        "Regrasja polega na stworzeniu modelu opisującego zależność między zmiennymi. Posiadając taki model możemy przewidywać wartość  jednej zmiennej ciągłej na podstawie innych zmienneych. \n",
        "\n",
        "Poniższy notatnik demonstruje:\n",
        "1. Metody regresji liniowej i wielomianowej z użyciem pakietu scikit-learn\n",
        "2. Tworzenie modelu (fit), predykcję wartości (predict) oraz ocenę jakości predykcji (MSE. $R^2$-score)\n",
        "3. Problem przeuczenia (overfitting) oraz sposoby redukcji tego problemu za pomocą regularyzacji\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ma-sUD1Qz4N"
      },
      "source": [
        "## Generowanie danych treningowych\n",
        "\n",
        "Stworzymy najpierw sztuczne dane, na których zbudujemy model regresyjny\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NsPQDzaQz4N"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgH8s_ZGQz4O"
      },
      "source": [
        "Zdefinujmy funkcję `true_function()`, która posłuży do wygenerowania danych do których będziemy dopasowywali nasz model. \n",
        "\n",
        "$$ f(x) = \\cos \\left(1.5 \\cdot \\pi \\cdot  x\\right) $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtkEloLVQz4O"
      },
      "source": [
        "def true_function(x):\n",
        "    return np.cos(1.5 * np.pi * x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDa6qMP5Qz4O"
      },
      "source": [
        "Wygenerujmy próbkę danych `x` oraz wyznaczmy wartości funkcji `y` dla tych danych.   \n",
        "Będziemy szukać zależności `x ~ y`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUiI3emhQz4P"
      },
      "source": [
        "Zainicjalizujmy najpierw ziarno dla funkcji losującej, aby za każdym razem otrzymać *te same* ale losowe dane. Często się to przydaje, gdy operujemy na losowych danych, ale chcemy zagwarantować powtarzalność wyników. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF0EXZ77Qz4P"
      },
      "source": [
        "np.random.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnIIwTUQQz4P"
      },
      "source": [
        "n_samples = 30\n",
        "x = np.sort(np.random.rand(n_samples, 1))\n",
        "y = true_function(x) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFFYNaisQz4P"
      },
      "source": [
        "Narysujmy tą funkcję oraz wygenerowane punkty."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI3DcbTbQz4P"
      },
      "source": [
        "#przedział do 'gęstego' narysowania funkcji,\n",
        "x_range = np.linspace(0, 1, 100)\n",
        "\n",
        "# operacja reshape tworzy transpozycje wektora, otrzymujemy macierzy o wymiarach (100, 1), \n",
        "# taka postać jest wymagana później przez model regresyjny LinearRegression()\n",
        "x_range = np.reshape(x_range, (-1, 1))\n",
        "\n",
        "plt.plot(x_range, true_function(x_range), label='funkcja prawdziwa')\n",
        "plt.plot(x, y, 'ro', label='Punkty treningowe')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "700eQxcOQz4Q"
      },
      "source": [
        "Dodajmy trochę szumu do danych aby utrudnić problem dopasowania modelu w naszym przykładzie. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZcEbq-6Qz4Q"
      },
      "source": [
        "y = true_function(x) + np.random.randn(n_samples, 1) * 0.1\n",
        "\n",
        "plt.plot(x_range, true_function(x_range))\n",
        "\n",
        "plt.plot(x, y, 'ro',)\n",
        "plt.legend(['funkcja prawdziwa','punkty uczące'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXFkTeUGQz4Q"
      },
      "source": [
        "## Model liniowy\n",
        "\n",
        "Dopasujmy do naszych danych model liniowy dla jednej zmiennej \n",
        "\n",
        "$$ f(x) = x w_1 + w_0 $$\n",
        "\n",
        "Zadanie polega na znalezieniu takich parametrów $w_1$ i $w_0$ definiujących linię aby błąd popełniany przez tą funkcję był jak najmniejszy, tzn. chcemy aby punkty danych leżały w jak najmniejszej odległości od dopasowanej linii.  Funkcja kosztu (błędu) to suma kwadratów różnic między punktem prawdziwym $y_i$ a tym uzyskanym z modelu $f(x_i)$:\n",
        "\n",
        "$$L(y, f(x,w)) = \\sum_{i=1}^N \\|y_i - f(x_i)\\|^2,$$\n",
        "\n",
        "Zadanie polega więc na znalezieniu takich $w_1$ i $w_0$, które minimalizują wartość błędu $L$. W celu wyznaczenia tego minimum wykorzystamy algorytm regresji liniowej dostępny w pakiecie scikit-learn [LinearRegression()](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfafCekiQz4Q"
      },
      "source": [
        "## Regresja wielu zmiennych \n",
        "\n",
        "Ogólna postać modelu regrasji liniowej wielowymiarowej  \n",
        "\n",
        "$$f(\\mathbf{x}) = x_1 w_1 + x_2 w_2 + \\ldots + x_k w_k + w_0= \\mathbf{x}^T \\mathbf{w} + w_0$$\n",
        "\n",
        "gdzie dla $k$ zmiennych $\\mathbf{w}$ jest wektorem $[w_1, w_2, \\ldots, w_k]$ współczynników i wraz z wyrazem wolnym $w_0$ są szukanymi wartościami określającymi liniową zależność w przestrzeni $\\mathbb{R}^k$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzeFZqUVQz4R"
      },
      "source": [
        "## Liniowa regresja w scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqAwG1egQz4R"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Tworzymy obiekt realizujący liniową regresję\n",
        "regr = LinearRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMDGF68sQz4R"
      },
      "source": [
        "Metoda ``fit(x, y)`` modelu predykcyjnego uruchamia trening modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh98vkpKQz4R"
      },
      "source": [
        "# Dopasowanie modelu do danych (poszukiwanie minimum funkcji błedu)\n",
        "regr.fit(x, y)\n",
        "\n",
        "# Wyznaczone wspólczynniki regresji\n",
        "a = regr.coef_[0]           # wspólczynnik kierunkowy  \n",
        "b = regr.intercept_         # wspólczynnik przecięcia\n",
        "\n",
        "print(\"f(x) = %f x + %f\" % (a, b))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cBIJNsqQz4R"
      },
      "source": [
        "## Predykcja\n",
        "\n",
        "Metoda [predict()](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.predict) pozwala wyznaczyć przewidywaną wartość zmiennej wyjściowej dla dowonych wartości wejściowych `x` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2q4xOKtQz4R"
      },
      "source": [
        "regr.predict([[0.5]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8_Vd_REQz4S"
      },
      "source": [
        "# to samo\n",
        "print(a * 0.5 + b)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "vexpaWCMQz4S"
      },
      "source": [
        "y_pred = regr.predict(x_range)\n",
        "\n",
        "plt.plot(x_range, true_function(x_range), label='funkcja prawdziwa')\n",
        "plt.plot(x_range, y_pred, 'g--', label='regresja liniowa')\n",
        "plt.plot(x, y, 'ro', label='punkty uczące')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VoquzpYQz4S"
      },
      "source": [
        "# co sprowadza się w tym przypadku do operacji\n",
        "y_lin = a * x_range + b      # model liniowy zalezosci X ~ Y\n",
        "\n",
        "np.alltrue(y_pred == y_lin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFgxWbYuQz4S"
      },
      "source": [
        "## Regresja wielomianowa\n",
        "\n",
        "Model liniowy w tym przypadku jest daleki od ideału. Spróbujmy dopasować do danych funkcję wielomianową.\n",
        "\n",
        "$$ f(x) = x^k w_k + x^{k-1} w_{k-1} + \\ldots + x w_1 + w_0 $$\n",
        "\n",
        "gdzie $k$ określa stopień wielomianu.  \n",
        "Dla $k=1$ otrzymamy znowu model liniowy, dla $k=2$ parabolę, itd.\n",
        "\n",
        "Jak widać sprowadza się to do znalezienia wspólczynników $w_i$ liniowego modelu dla $k$ zmiennych, gdzie zmienne są postaci $x, x^2, \\ldots, x^k$.\n",
        "\n",
        "Wykorzystajmy funkcję [PolynomialFeatures()](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) do przekształcenia danych $x$ do takiej postaci."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI16kSaRQz4T"
      },
      "source": [
        "### Transformacja wielomianowa w scikit-learn\n",
        "\n",
        "Stwórzmy model liniowy dla zmiennych $x^2$ i $x$, co odpowiada dopasowaniu wielomianu 2 stopnia $$f(x) = w_2 x^2 + w_1 x + w_0$$\n",
        "\n",
        "[PolynomialFeatures()](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) jest transformatorem danych, API takich modeli w scikit-learn wygląda tak: \n",
        "* ``fit(x)`` - trening (dopasowanie) modelu transformacji na danych treningowych\n",
        "* ``transform(x)`` - transformacja (nowych) danych za pomocą modelu uzyskanego w treningu\n",
        "* ``fit_transform(x)`` - trening i transformacja danych treningowych "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjjKHZsYQz4T"
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures \n",
        "\n",
        "# regresja wielomianem stopnia 2 \n",
        "poly2 = PolynomialFeatures(degree = 2) \n",
        "x_poly2 = poly2.fit_transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McYqw-VuQz4T"
      },
      "source": [
        "# sprawdźmy \n",
        "x_tmp =  np.hstack( [ np.ones(x.shape), x, x*x] )   #  x zamienione na 1, x, x^2\n",
        "np.alltrue(x_tmp == x_poly2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2orCXzOQz4T"
      },
      "source": [
        "regr2 = LinearRegression()\n",
        "regr2.fit(x_poly2, y)\n",
        "\n",
        "plt.plot(x_range, true_function(x_range), label='prawdziwa funkcja')\n",
        "plt.plot(x_range, regr2.predict(poly2.transform(x_range)), 'g--', label='regresja wielomianem stopnia 2')\n",
        "plt.plot(x, y, 'ro', label='punkty treningowe')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print('%d współczynniki regresji: %s'  % ( len(regr2.coef_[0]), str(regr2.coef_[0])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GmYx-lfQz4T"
      },
      "source": [
        "Wynik wygląda lepiej. Spróbujmy dopasować wielomian wyższego rzędu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n9sPIesQz4T"
      },
      "source": [
        "### Dopasowanie wielomianu stopnia 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z-LfPOeQz4U"
      },
      "source": [
        "poly3 = PolynomialFeatures(degree = 3) \n",
        "x_poly3 = poly3.fit_transform(x) \n",
        "\n",
        "regr3 = LinearRegression()\n",
        "regr3.fit(x_poly3, y)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "\n",
        "plt.plot(x_range, true_function(x_range), label='prawdziwa funkcja')\n",
        "plt.plot(x_range, regr2.predict(poly2.transform(x_range)), 'g--', label='regresja wielomianowa d=2')\n",
        "plt.plot(x_range, regr3.predict(poly3.transform(x_range)), 'm--', label='regresja wielomianowa d=3')\n",
        "plt.plot(x, y, 'ro', label='punkty uczące')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print('%d współczynniki regresji: %s'  % ( len(regr3.coef_[0]), str(regr3.coef_[0])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEYHIVaDQz4U"
      },
      "source": [
        "## Przeuczenie\n",
        "\n",
        "Wygląda na to, że jeśli będziemy dopasowywać wielomian coraz wyższego stopnia, otrzymamy coraz lepszą aproksymację danych. Niemniej jednak zwiększanie stopnia wielomianu, a co za tym idzie 'poziomu skomplikowania' naszego modelu, będzie powodować zbyt duże dopasowanie się do danych i zbyt małe możliwości generalizacji modelu. W szczególności możemy mówić o dwóch fenomenach jeżeli uczymy się parametrów modelu z danych:\n",
        "\n",
        "* **underfit** - model jest zbyt 'prosty' aby uchwycić zależności między danymi\n",
        "* **overfit** (przeczenie)  - parametry naszego modelu 'nauczyły' się szumu, model jest zbyt dopasowany do danych treningowych\n",
        "\n",
        "![image.png](attachment:image.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNXuFJW0Qz4U"
      },
      "source": [
        "Istnieje zatem całkiem duże prawdopodobieństwo, że zwiększając stopień wielomianu dopasowaliśmy wielomian do szumu. Aby to zilustrować weźmy wielomian 16-go stopnia:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viBL3WqZQz4U"
      },
      "source": [
        "poly16 = PolynomialFeatures(degree = 16)\n",
        "x_poly16 = poly16.fit_transform(x)\n",
        "\n",
        "regr16 = LinearRegression() \n",
        "regr16.fit(x_poly16, y)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(x_range, true_function(x_range), label='prawdziwa funkcja')\n",
        "plt.plot(x_range, regr16.predict(poly16.fit_transform(x_range)), 'b--', label='regresja wielomianowa d=16 (przeuczenie)')\n",
        "plt.plot(x, y, 'ro', label='punkty uczące')\n",
        "plt.ylim((-1.2, 1.7))\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print('%d współczynników regresji: %s'  % ( len(regr16.coef_[0]), str(regr16.coef_[0])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMNCfE3oQz4U"
      },
      "source": [
        "## Ocena modelu\n",
        "### Błąd MSE\n",
        "\n",
        "Podstawową miarą służącą do oceny modelu regresyjnego jest średnia wartość funkcji kosztu, czyli tzw. **błąd średniokwadratowy MSE** (*mean squared error*):\n",
        "\n",
        "$$ MSE = \\frac{1}{n} \\sum_{i=1}^n \\left( y_i - f(x_i) \\right)^2 $$\n",
        "\n",
        "W przypadku idealnego dopasowania, gdy wszystkie $y_i$ są bezbłędnie dopasowane przez funkcję $f(x_i)$, bład MSE ma wartość 0. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qQXektwQz4U"
      },
      "source": [
        "### Miara $R^2$\n",
        "\n",
        "Drugą powszechnie używaną miarą oceny jest **współczynnik determinacji $R^2$**:\n",
        "\n",
        "$$ R^2 = \\frac{\\sum_{i=1}^n \\left( f(x_i) - \\bar{y}_i\\right)^2}{\\sum_{i=1}^n \\left( y_i - \\bar{y}_i\\right)^2} > 0$$\n",
        "\n",
        "gdzie $\\bar{y}$ to średnia wartość odpowiedzi $y_i$ dla wszystkich punktów w danych $i=1,\\ldots,n$.  \n",
        "\n",
        "Im większa wartość współczynnika $R^2$ tym lepsze dopasowanie $f(x)$ do danych.\n",
        "\n",
        "W przypadku bezbłędnego dopasowania $R^2=1$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zff5ajWVQz4V"
      },
      "source": [
        "### Meryki oceny w scikit-learn\n",
        "\n",
        "Pakiet ``sklearn.metrics`` zawiera szereg metryk to oceny modeli, m. in. metryki do oceny modeli regresyjnych:\n",
        "* funkcja ``mean_squared_error(y_true, y_pred)``\n",
        "* funkcja ``r2_score(y_true, y_pred)``\n",
        "\n",
        "Modele predykcyjne posiadają też metodę ``score(x, y)`` do wyznaczania oceny (dla ``LinearRegression()`` domyślnie $R^2$) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Sr7O79DQz4V"
      },
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "y_pred = regr.predict(x)\n",
        "y_regr2_pred = regr2.predict(poly2.transform(x))\n",
        "y_regr3_pred = regr3.predict(poly3.transform(x))\n",
        "y_regr16_pred = regr16.predict(poly16.transform(x))\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "columns = ['Model', 'MSE', 'R2']\n",
        "data = pd.DataFrame(columns=columns)\n",
        "data.loc[0] = ['linear',   mean_squared_error(y, y_pred),        r2_score(y, y_pred)        ] \n",
        "data.loc[1] = ['poly 2',   mean_squared_error(y, y_regr2_pred),  r2_score(y, y_regr2_pred)  ] \n",
        "data.loc[2] = ['poly 3',   mean_squared_error(y, y_regr3_pred),  r2_score(y, y_regr3_pred)  ] \n",
        "data.loc[3] = ['poly 16',  mean_squared_error(y, y_regr16_pred), r2_score(y, y_regr16_pred) ] \n",
        "\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz8FKQtmQz4V"
      },
      "source": [
        "# R2-score za pomoca metody score() modelu\n",
        "regr.score(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysePEpdFQz4V"
      },
      "source": [
        "import seaborn as sb\n",
        "sb.barplot(data=data, x='Model', y='MSE')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywgvq9rBQz4W"
      },
      "source": [
        "sb.barplot(data=data, x='Model', y='R2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH1_yASLQz4W"
      },
      "source": [
        "Obliczanie błędu MSE na danych `(X, Y)`, na których dokonano dopasowania modelu nie jest wiarygodną oceną. Widać, że model najbardziej złożony i przeuczony ma najmniejszy błąd MSE. Znając prawdziwą funkcję, możemy obliczyć błąd popełniany przez model, jednak w rzeczywistych zastosowaniach nie mamy dostępu do prawdziwej funkcji, gdyż to właśnie tą funkcję próbujemy odkryć. Potrzebujemy danych do testowania. W przypadku, gdy mamy do dyspozycji dużo danych wejściowych możemy je podzielić na część **treningową** oraz część **testową**. Wówczas model dopasowany na zbiorze treningowym może zostać oceniony na części testowej, która nie została użyta do stworzenia modelu. Jeżeli model regresyjny będzie posiadał mały błąd również na danych testowych to znaczy, że znaleźliśmy ogólną regułę, prawdziwą dla tego typu danych (tzn.model generalizuje)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvK1Z_a9Qz4W"
      },
      "source": [
        "### Ocena na danych testowych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9dryKmoQz4W"
      },
      "source": [
        "Załóżmy, że posiadamy osobny fragment naszych wygenerowanych danych, który nie brał udziału w tworzeniu modelu. W naszym przypadku wygenerujemy nowe obserwacje, które posłużą w roli zbioru testowego."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ6lSPyCQz4W"
      },
      "source": [
        "x_test = np.sort(np.random.rand(100, 1))\n",
        "y_test = true_function(x_test) + np.random.randn(100, 1) * 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G075rtdhQz4W"
      },
      "source": [
        "Dokonajmy oceny na zbiorze tesowym"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td7WbU91Qz4W"
      },
      "source": [
        "y_test_pred = regr.predict(x_test)\n",
        "y_regr2_test_pred = regr2.predict(poly2.fit_transform(x_test))\n",
        "y_regr3_test_pred = regr3.predict(poly3.fit_transform(x_test))\n",
        "y_regr16_test_pred = regr16.predict(poly16.fit_transform(x_test))\n",
        "\n",
        "mse_test = [ \n",
        "     mean_squared_error(y_test, y_test_pred),\n",
        "     mean_squared_error(y_test, y_regr2_test_pred),\n",
        "     mean_squared_error(y_test, y_regr3_test_pred),\n",
        "     mean_squared_error(y_test, y_regr16_test_pred)\n",
        "]\n",
        "\n",
        "data['MSE test'] = mse_test\n",
        "\n",
        "sb.barplot(data=data, x='Model', y='MSE test')\n",
        "\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMOJAvGTQz4X"
      },
      "source": [
        "Jak można było się spodziewać model o największej złożoności (wielomian stopnia 16) ma największy błąd na zbiorze testowym. Na zbiorze treningowym jego błąd był bardzo mały, to znaczy, że model jest przeuczony i zbytnio dopasował się do danych w zbiorze uczącym. Najlepszą generalizację (zdolność do popranego przewidywania `y` na nowych danych) w tym wypadku miała regresja wielomianowa stopnia 3.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenNexR4Qz4X"
      },
      "source": [
        "## Regularyzacja\n",
        "\n",
        "Metody regularyzacji mają za zadanie zminimalizować ryzyko przeuczenia modelu. W przypadku regresji powszechnie stosowanym podejściem jest dodanie do funkcji kosztu $L$ dodatkowego członu, który będzie wymuszał zmniejszanie wartości wag $w_i$. W szczególnym wypadku, gdy waga zmaleje do zera $w_i=0$ można uznać, że zmienna $i$-ta jest nieistotna dla modelowanej zależności (czynnik $w_i x_{ij}$ zanika). W ten sposób wymuszając zmniejszanie wartości wag w trakcie optymalizacji preferowane są modele o mniejszej złożoności (część wag $w_i$ zaniknie lub będzie miała małe wartości)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdsPygTuQz4X"
      },
      "source": [
        "### Regresja grzbietowa\n",
        "\n",
        "Regresja grzbietowa (*Ridge regression*) polega poszukiwaniu parametrów $w_i$ poprzez minimalizację poniższej funkcji kosztu\n",
        "$$L_{\\textrm{ridge}} = \\sum_{i=1}^N \\|y_i - f(x_i)\\|^2 + \\alpha \\|w\\|^2 $$\n",
        "\n",
        "gdzie $\\alpha > 0$ jest parametrem określającym siłę regularyzacji.  \n",
        "Dla $\\alpha=0$ człon regularyzacyjny zanika i regresja grzbietowa zamienia się w zwykła regresję liniową. Zazwyczaj $\\alpha$ jest małą wartością dodatnią np. 0.01.\n",
        "Minimalizacja powyższej funkcji kosztu dąży do minimalizacji błędu MSE (pierwszy człon) oraz do zanikania wartości wag (drugi człon).\n",
        "\n",
        "Spróbujmy zobaczyć jaki wynik uzyskamy dla regresji wielomianowej stopnia 16 w naszym przypadku, gdy zastosujemy regularyzację."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0qgVOSDQz4X"
      },
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "ridge = linear_model.Ridge(alpha=0.02)\n",
        "ridge.fit(x_poly16, y)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "plt.plot(x_range, true_function(x_range), label='prawdziwa funkcja')\n",
        "plt.plot(x_range, ridge.predict(poly16.fit_transform(x_range)), 'b--', label='ridge (alpha=0.02)')\n",
        "# plt.plot(x_range, regr16.predict(poly16.fit_transform(x_range)), 'g--', label='poly 16')\n",
        "plt.plot(x, y, 'ro', label='punkty treningowe')\n",
        "plt.ylim((-1.2, 1.7))\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8QpPW2EQz4X"
      },
      "source": [
        "y_ridge_pred_test = ridge.predict(poly16.fit_transform(x_test))\n",
        "y_ridge_pred_train = ridge.predict(poly16.fit_transform(x))\n",
        "                             \n",
        "data.loc[4] = ['ridge',  \n",
        "               mean_squared_error(y, y_ridge_pred_train), \n",
        "               r2_score(y, y_ridge_pred_train),\n",
        "               mean_squared_error(y_test, y_ridge_pred_test)] \n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdQrVfl_Qz4X"
      },
      "source": [
        "sb.barplot(data=data, x='Model', y='MSE test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWkNfkV0Qz4X"
      },
      "source": [
        "Błąd na zbiorze testowym wskazuje, że dopasowanie wielomianu stopnia 16 do naszego przykładu z zastosowaniem regularyzacji grzbietowej osiągnął zbliżony wynik do wielomianu stopnia 3. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1bunY65Qz4Z"
      },
      "source": [
        "Zobaczmy jak wyglądają wartości bezwzględne uzyskanych parametrów $w_i$ dla modelu z regularyzacją i bez regularyzacji."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eXOP-l8Qz4Z"
      },
      "source": [
        "print('Suma wartości wag modelu z regularyzacją grzbietową:', np.absolute(ridge.coef_[0]).sum())\n",
        "print('Suma wartości wag modelu bez regularyzacji:', np.absolute(regr16.coef_[0]).sum())\n",
        "\n",
        "plt.bar(range(len(regr16.coef_[0])), np.absolute(regr16.coef_[0]))\n",
        "plt.title('Współczynniki regresji bez regularyzacji')\n",
        "plt.show()\n",
        "plt.bar(range(len(ridge.coef_[0])), np.absolute(ridge.coef_[0]))\n",
        "plt.title('Współczynniki regresji grzbietowej (z regularyzacją)')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK1-naSIQz4Z"
      },
      "source": [
        "### Regresja Lasso\n",
        "\n",
        "Regresja metodą Lasso jest bardzo podobna do regresji grzbietowej, jednak zamiast normy $L_2$ w czynniku regularyzacyjnym występuje norma $L_1$:\n",
        "\n",
        "$$L_{\\textrm{lasso}} = \\sum_{i=1}^N \\|y_i - f(x_i)\\|^2 + \\alpha \\|w\\|_1 $$\n",
        "\n",
        "Tego typu regularyzacja również preferuje rozwiązania z małymi wartościami wag, jednak w odróżnieniu od regresji grzbietowej otrzymana reprezentacja jest \"rzadsza\", tzn. większa liczba  spółczynników $w_i$ jest redukowanych do 0.\n",
        "\n",
        "Wykonajmy ponownie dopasowanie wielomianem stopnia 16 tym razem z regularyzacją Lasso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fbj8cyHsQz4Z"
      },
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "lasso = linear_model.Lasso(alpha=0.01)\n",
        "lasso.fit(x_poly16, y)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "plt.plot(x_range, true_function(x_range), label='funkcja prawdziwa')\n",
        "plt.plot(x_range, lasso.predict(poly16.fit_transform(x_range)), 'b--', label='regresja lasso (alpha=0.01)')\n",
        "# plt.plot(x_range, regr16.predict(poly16.fit_transform(x_range)), 'g--', label='poly 16')\n",
        "plt.plot(x, y, 'ro', label='punkty treningowe')\n",
        "plt.ylim((-1.2, 1.7))\n",
        "plt.legend()\n",
        "plt.show()                        \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VBcnUyAQz4a"
      },
      "source": [
        "y_pred_train_lasso = lasso.predict(poly16.fit_transform(x))\n",
        "y_pred_test_lasso = lasso.predict(poly16.fit_transform(x_test))\n",
        "\n",
        "data.loc[5] = ['lasso',  \n",
        "               mean_squared_error(y, y_pred_train_lasso), \n",
        "               r2_score(y, y_pred_train_lasso),\n",
        "               mean_squared_error(y_test, y_pred_test_lasso)] \n",
        "\n",
        "sb.barplot(data=data, x='Model', y='MSE test')\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GYi3kkDQz4a"
      },
      "source": [
        "Uzyskany wynik jest gorszy od modelu regresji grzbietowej ale jest też o wiele lepszy od modelu, który nie był poddany regularyzacji. Odpowiedni dobór siły regularyzacji $\\alpha$ powinien pozwolić uzyskać wynik zbliżony a może i lepszy od regresji grzbietowej. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCbnUcD9Qz4a"
      },
      "source": [
        "Porównanie wartości współczynników uzyskanych obiema metodami regularyzacji."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dkmshjvQz4a"
      },
      "source": [
        "print('Współczynniki modelu regresji grzbietowej')\n",
        "print(ridge.coef_[0])\n",
        "\n",
        "plt.bar(range(len(ridge.coef_[0])), np.absolute(ridge.coef_[0]))\n",
        "plt.title('Regresja grzebietowa')\n",
        "plt.show()\n",
        "\n",
        "print('Współczynniki regresji modelu lasso')\n",
        "print(lasso.coef_)\n",
        "\n",
        "plt.bar(range(len(lasso.coef_)), np.absolute(lasso.coef_))\n",
        "plt.title('Regresja lasso')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2McCUAJQz4a"
      },
      "source": [
        "W przypadku regularyzacji Lasso tylko 3 współczynniki są niezerowe, tzn. tylko te 3 zmienne wystarczą do uzyskania predykcji wartości `y` przy zachowaniu niewielkiego błędu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlSLMd4UQz4a"
      },
      "source": [
        "# Zestaw danych Housing\n",
        "\n",
        "Zbiór danych cen mieszkań w Bostonie (506 wierszy i 14 kolumn). Każdy wiersz reprezentuje dom znajdujący się w Bostonie w stanie Massachusetts w 1978 r.  \n",
        "Celem jest oszacowania średniej wartości domu (MEDV). \n",
        "\n",
        "Źródło: [https://archive.ics.uci.edu/ml/datasets/Housing](https://archive.ics.uci.edu/ml/datasets/Housing)\n",
        "\n",
        "Atrybuty:\n",
        "    \n",
        "<pre>\n",
        "1. CRIM      współczynnik przestępczości per capita na każde miasteczko\n",
        "2. ZN        odsetek działek przekraczających 25 000 stóp kwadratowych (≈ 2533 metrów kwadratowych).\n",
        "3. INDUS     odsetek terenów przeznaczonych na przemysł niedetaliczny na każde miasteczko\n",
        "4. CHAS      zmienna zerojedynkowa określająca rzekę Charles (przyjmuje wartość 1, gdy na danym terenie znajduje się koryto      \n",
        "             rzeki)\n",
        "5. NOX       stężenie tlenków azotu (w częściach na 10 milionów)\n",
        "6. RM        średnia liczba pomieszczeń na dom\n",
        "7. AGE       odsetek zamieszkałych budynków wybudowanych przed 1940 rokiem\n",
        "8. DIS       ważona odległość do pięciu bostońskich urzędów pracy\n",
        "9. RAD       wskaźnik dostępności do głównych arterii komunikacyjnych\n",
        "10. TAX      pełna wartość podatku od nieruchomości na każde 10 000 dolarów\n",
        "11. PTRATIO  stosunek liczby uczniów do nauczycieli na każde miasteczko\n",
        "12. B        parametr wyliczany ze wzoru 1000(Bk - 0.63)^2, gdzie Bk oznacza odsetek osób pochodzenia afroamerykańskiego \n",
        "             zamieszkujących dane miasteczko \n",
        "13. LSTAT    odsetek ubogiej części społeczeństwa\n",
        "14. MEDV     mediana wartości zamieszkanych domów wyrażona w tysiącach dolarów\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMrir151Qz4a"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data', \n",
        "                 header=None, sep='\\s+')\n",
        "\n",
        "df.columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', \n",
        "              'NOX', 'RM', 'AGE', 'DIS', 'RAD', \n",
        "              'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oivamFT-Qz4b"
      },
      "source": [
        "## Podstawowe informacje o danych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5frahbloQz4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3d115bc-c703-4afb-a238-70353be05404"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 442 entries, 0 to 441\n",
            "Data columns (total 11 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   AGE     442 non-null    int64  \n",
            " 1   SEX     442 non-null    int64  \n",
            " 2   BMI     442 non-null    float64\n",
            " 3   BP      442 non-null    float64\n",
            " 4   S1      442 non-null    int64  \n",
            " 5   S2      442 non-null    float64\n",
            " 6   S3      442 non-null    float64\n",
            " 7   S4      442 non-null    float64\n",
            " 8   S5      442 non-null    float64\n",
            " 9   S6      442 non-null    int64  \n",
            " 10  Y       442 non-null    int64  \n",
            "dtypes: float64(6), int64(5)\n",
            "memory usage: 38.1 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSOyDKMBQz4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "7bb4b17a-6b38-4c3d-f0ee-47de7e97bd35"
      },
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "df.boxplot()\n",
        "display(df.describe())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-4c40061a908f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeaTXC8LQz4b"
      },
      "source": [
        "df.isna().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfpBoqQoQz4b"
      },
      "source": [
        "## Wsółczynnik korelacji liniowej\n",
        "\n",
        "Korelacja liniowa [Pearsona](https://pl.wikipedia.org/wiki/Wsp%C3%B3%C5%82czynnik_korelacji_Pearsona) \n",
        "$$\n",
        "r_{x y}=\\frac{\\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)\\left(y_{i}-\\bar{y}\\right)}{\\sqrt{\\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}} \\sqrt{\\sum_{i=1}^{n}\\left(y_{i}-\\bar{y}\\right)^{2}}}\n",
        "$$\n",
        "\n",
        "Wartość bliska 1 lub -1 wskazuje o silnej korelacji linowej\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prq1rJdHQz4c"
      },
      "source": [
        "#Sort correlations\n",
        "correlations = df.corr()\n",
        "correlations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHjfJ5jdQz4c"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(correlations, cmap='coolwarm', vmin=-1, vmax=1, square=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77wDycwzQz4c"
      },
      "source": [
        "# Wspólczynniki korelacji dla zmiennej MEDV\n",
        "\n",
        "corr_mdev = correlations['MEDV'].sort_values()\n",
        "corr_mdev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE2GWl5sQz4c"
      },
      "source": [
        "## Wizualizowanie ważnych elementów zestawu danych\n",
        "\n",
        "Wybieżmy zmienne o wysokim wspólczynniku korelacji (>0.5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PE_5s4VQz4c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cols = ['LSTAT', 'PTRATIO', 'RM', 'MEDV']\n",
        "\n",
        "sns.pairplot(df[cols], height=2.5)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6X3wb4XQz4c"
      },
      "source": [
        "cm = df[cols].corr()\n",
        "# sns.set(font_scale=1.0)\n",
        "plt.figure(figsize=(10,10))\n",
        "hm = sns.heatmap(cm, \n",
        "            cbar=True,\n",
        "            annot=True, \n",
        "            square=True,\n",
        "            fmt='.2f',\n",
        "            annot_kws={'size': 10},\n",
        "            yticklabels=cols,\n",
        "            xticklabels=cols,\n",
        "            cmap='coolwarm', vmin=-1, vmax = 1)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNpHRfNYQz4c"
      },
      "source": [
        "## Wydzielenie zbioru testowego\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0snuTDGQz4d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop(columns='MEDV')\n",
        "y = df['MEDV']\n",
        "\n",
        "#Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "print('Ilość przypadków treningowych %d ' % len(X_train))\n",
        "print('Ilość przypadków testowych    %d ' % len(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0rJwnSVQz4d"
      },
      "source": [
        "## Model dla pojedynczej zmiennej"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkxNFOuAQz4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "565009b3-c9da-49de-a2a5-66938f1af1a8"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr = linear_model.LinearRegression()\n",
        "lr.fit(X_train[['RM']],  y_train)\n",
        "\n",
        "print('Nachylenie: %.3f' % lr.coef_[0])\n",
        "print('Punkt przecięcia: %.3f' % lr.intercept_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-be5f801122cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RM'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'linear_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLfbL8KzQz4d"
      },
      "source": [
        "plt.scatter(X_train[['RM']], y_train, c='lightblue')\n",
        "\n",
        "x_range = [X_train[['RM']].min().values, X_train[['RM']].max().values ]\n",
        "plt.plot(x_range, lr.predict(x_range), color='red', linewidth=2) \n",
        "\n",
        "plt.xlabel('Uśredniona liczba pomieszczeń [RM]')\n",
        "plt.ylabel('Cena w tysiącach dolarów [MEDV]')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo8PfZsVQz4d"
      },
      "source": [
        "num_rooms = [[ 5 ]]\n",
        "price = lr.predict(num_rooms)\n",
        "print(\"Cena w tysiącach dolarów: %.3f\" % price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuaZAkyMQz4d"
      },
      "source": [
        "# ocena modelu\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "y_train_pred = lr.predict(X_train[['RM']])\n",
        "y_test_pred = lr.predict(X_test[['RM']])\n",
        "\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "mse_test  = mean_squared_error(y_test, y_test_pred)\n",
        "print('MSE na próbkach uczących: %.3f, testowych: %.3f' % (mse_train, mse_test))\n",
        "\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "r2_test  = r2_score(y_test, y_test_pred)\n",
        "print('Współczynnik R^2 dla danych uczących: %.3f, testowych: %.3f' % (r2_train, r2_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz5JRCQYQz4d"
      },
      "source": [
        "wyniki = pd.DataFrame(columns =['MSE train', 'MSE test', 'R2 train', 'R2 test' ])\n",
        "wyniki.loc['LR zmienna [RM]'] = [mse_train, mse_test, r2_train, r2_test ]\n",
        "wyniki"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uDeppE6Qz4d"
      },
      "source": [
        "## Model regresji liniowej dla wybranych zmiennych\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yu242lIwQz4e"
      },
      "source": [
        "# wybierzmy 3 zmienne o najwiekszym wsp. korelacji\n",
        "cols = ['LSTAT', 'PTRATIO', 'RM']\n",
        "\n",
        "lr = linear_model.LinearRegression()\n",
        "lr.fit(X_train[cols],  y_train)\n",
        "\n",
        "y_train_pred = lr.predict(X_train[cols])\n",
        "y_test_pred = lr.predict(X_test[cols])\n",
        "\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "mse_test  = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "r2_test  = r2_score(y_test, y_test_pred)\n",
        "\n",
        "wyniki.loc['LR zmienne %s' % str(cols)] = [ mse_train, mse_test, r2_train, r2_test ]\n",
        "wyniki"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYLnFfDiQz4e"
      },
      "source": [
        "## Wykres residuów (wartości resztowe)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3rsO8NjQz4e"
      },
      "source": [
        "plt.scatter(y_train_pred,  y_train_pred - y_train, c='blue', marker='o', label='Dane uczące')\n",
        "plt.scatter(y_test_pred,  y_test_pred - y_test, c='lightgreen', marker='s', label='Dane testowe')\n",
        "plt.xlabel('Przewidywane wartości')\n",
        "plt.ylabel('Wartości resztowe')\n",
        "plt.legend(loc='upper left')\n",
        "plt.hlines(y=0, xmin=-10, xmax=50, lw=2, color='red')\n",
        "plt.xlim([-10, 50])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZYzmeE5Qz4e"
      },
      "source": [
        "## Model regresji dla wszystkich zmienneych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KEiEfBYQz4e"
      },
      "source": [
        "lr = linear_model.LinearRegression()\n",
        "lr.fit(X_train,  y_train)\n",
        "\n",
        "y_train_pred = lr.predict(X_train)\n",
        "y_test_pred = lr.predict(X_test)\n",
        "\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "mse_test  = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "r2_test  = r2_score(y_test, y_test_pred)\n",
        "\n",
        "wyniki.loc['LR wszystkie zmienne'] = [ mse_train, mse_test, r2_train, r2_test ]\n",
        "wyniki"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I35JIQqVQz4f"
      },
      "source": [
        "# lasso dla wszystkich zmiennych \n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "lasso = Lasso()\n",
        "lasso.fit(X_train, y_train)\n",
        "y_train_pred = lasso.predict(X_train)\n",
        "y_test_pred = lasso.predict(X_test)\n",
        "print(lasso.coef_)\n",
        "\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "mse_test  = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "r2_test  = r2_score(y_test, y_test_pred)\n",
        "\n",
        "wyniki.loc['Lasso wszystkie zmienne'] = [ mse_train, mse_test, r2_train, r2_test ]\n",
        "wyniki"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjQ0ANgYQz4f"
      },
      "source": [
        "# silniejsza regularyzacja lasso\n",
        "lasso = Lasso(alpha=0.1)\n",
        "lasso.fit(X_train, y_train)\n",
        "y_train_pred = lasso.predict(X_train)\n",
        "y_test_pred = lasso.predict(X_test)\n",
        "print(lasso.coef_)\n",
        "\n",
        "wyniki.loc['Lasso alpha=0.1 wszystkie zmienne'] = [ mean_squared_error(y_train, y_train_pred), \n",
        "                                                   mean_squared_error(y_test, y_test_pred), \n",
        "                                                   r2_score(y_train, y_train_pred), \n",
        "                                                   r2_score(y_test, y_test_pred) ]\n",
        "wyniki"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbGb8W9uQz4f"
      },
      "source": [
        "## Modelowanie nieliniowych zależności"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At77GEhYQz4f"
      },
      "source": [
        "# zmienna 'LSTAT'\n",
        "\n",
        "sns.lmplot(data=df, x='LSTAT', y='MEDV')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdjoDw8SQz4f"
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures \n",
        "\n",
        "# tworzy wielomianowe cechy\n",
        "quadratic = PolynomialFeatures(degree=2)\n",
        "X_quad_train = quadratic.fit_transform(X_train[['LSTAT']])\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_quad_train, y_train)\n",
        "\n",
        "y_train_pred = lr.predict(X_quad_train)\n",
        "y_test_pred = lr.predict(quadratic.transform(X_test[['LSTAT']]))\n",
        "\n",
        "wyniki.loc['LR kwadratowe (d=2) [LSTAT]'] = [ mean_squared_error(y_train, y_train_pred), \n",
        "                                              mean_squared_error(y_test, y_test_pred), \n",
        "                                              r2_score(y_train, y_train_pred), \n",
        "                                              r2_score(y_test, y_test_pred) ]\n",
        "wyniki"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15bhjhHyQz4f"
      },
      "source": [
        "X_fit = np.arange(X_train[['LSTAT']].values.min(), X_train[['LSTAT']].values.max(), 1)[:, np.newaxis]\n",
        "y_quad_fit = lr.predict(quadratic.transform(X_fit))\n",
        "\n",
        "# tworzy wynikowy wykres\n",
        "plt.scatter(X_train[['LSTAT']], y_train, label='Punkty uczące', color='orange')\n",
        "plt.scatter(X_test[['LSTAT']], y_test, label='Punkty testowe', color='green')\n",
        "\n",
        "plt.plot(X_fit, y_quad_fit, \n",
        "         label='Kwadratowe (d = 2)',\n",
        "         color='red', \n",
        "         lw=2,\n",
        "         linestyle='-')\n",
        "\n",
        "plt.xlabel('Odsetek uboższej części społeczeństwa [LSTAT]')\n",
        "plt.ylabel('Cena w tysiącach dolarów [MEDV]')\n",
        "plt.legend(loc='upper right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fpzs4iFaQz4g"
      },
      "source": [
        "# przekształcenie cechy (zmiennej) aby uzyskać liniowaą zalezność\n",
        "X_log_train = np.log(X_train[['LSTAT']].values)\n",
        "\n",
        "lr.fit(X_log_train, y_train)\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_log_train, y_train)\n",
        "\n",
        "y_train_pred = lr.predict(X_log_train)\n",
        "y_test_pred = lr.predict(np.log(X_test[['LSTAT']]))\n",
        "\n",
        "wyniki.loc['LR log([LSTAT])'] = [ mean_squared_error(y_train, y_train_pred), \n",
        "                                  mean_squared_error(y_test, y_test_pred), \n",
        "                                  r2_score(y_train, y_train_pred), \n",
        "                                  r2_score(y_test, y_test_pred) ]\n",
        "wyniki"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMX-VryUQz4g"
      },
      "source": [
        "X_fit = np.arange(X_log_train.min()-1, X_log_train.max()+1, 1)[:, np.newaxis]\n",
        "y_fit = lr.predict(X_fit)\n",
        "\n",
        "plt.scatter(X_log_train, y_train, label='Punkty uczące', color='orange')\n",
        "\n",
        "plt.plot(X_fit, y_fit, \n",
        "         label='Liniowe (d = 1)', \n",
        "         color='blue', \n",
        "         lw=2)\n",
        "\n",
        "plt.xlabel('log(odsetek uboższej części społeczeństwa [LSTAT])')\n",
        "plt.ylabel('Cena w tysiącachdolarów [MEDV]')\n",
        "plt.legend(loc='lower left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMgZnHztQz4g"
      },
      "source": [
        "## Zadanie \n",
        "\n",
        "Pod adresem https://www.fizyka.umk.pl/~grochu/wdm/files/diabetes.csv znajduje się plik zawierający dane `n=442` pacjentów chorych na cukrzycę (`diabetes`). Każdy przypadek opisany jest 10 zmiennymi numerycznymi:  wiek (`AGE`), płeć (`SEX`), wskaźnik masy ciała (`BMI`), średnie ciśnienie krwi (`BP`) i sześć pomiarów surowicy krwi (`S1 S2 S3 S4 S5 S6`). Ostatnia kolumna (zmienna `Y`) zawiera wartości określające stopnień zaawansowania choroby. Zadanie polega na zbudowaniu modeli regresji liniowej przewidujących wartość zmiennej `Y` zgodnie z poniższymi wytycznymi.\n",
        "\n",
        "1. Wczytaj plik i sprawdź, czy w danych występują braki oraz sprawdź, czy wszystkie zmienne są wartościami numerycznymi. Jeżeli zajdzie potrzeba usuń obserwacje zawierające braki a zmienne przetransformuj do postaci numerycznej."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egDSUbAsQz4g"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://www.fizyka.umk.pl/~grochu/wdm/files/diabetes.csv')\n",
        "\n",
        "print(df)\n",
        "\n",
        "df.info()\n",
        "\n",
        "df.isna().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cP6sH1BQz4g"
      },
      "source": [
        "2. Podziel dane na dwie części: treningową zawierającą 75% przypadków i testową zawierającą pozostałe 25% przypadków.   \n",
        "Modele regresji trenuj wyłacznie na części treningowej.  \n",
        "Do podziału danych możesz wykorzystać funkcję [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) z pakietu scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duZyIhE0Qz4g"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dfx = df.drop(columns = \"Y\")\n",
        "dfy = df[\"Y\"]\n",
        "\n",
        "dfx_train, dfx_test, dfy_train, dfy_test = train_test_split(dfx, dfy, train_size = 0.75, test_size = 0.25, random_state=0)\n",
        "\n",
        "print('Ilość przypadków treningowych %d ' % len(dfy_train))\n",
        "print('Ilość przypadków testowych    %d ' % len(dfy_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88StdkuEQz4g"
      },
      "source": [
        "3. Sporządź wykres parowy [pairplot()](https://seaborn.pydata.org/generated/seaborn.pairplot.html) zbioru treningowego i na jego podstawie wybierz jedną zmienną, która wydaje się posiadać liniową zależność względem zmiennej wyjściowej `Y`. Zbuduj model regresji liniowej dla wybranej zmiennej i wyznacz błąd MSE predykcji `Y` na zbiorze treningowym oraz na zbiorze testowym."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRqYDFoBQz4g"
      },
      "source": [
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#sns.pairplot(df)\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(dfx_train[['BMI']], dfy_train)\n",
        "\n",
        "print('Nachylenie: %.3f' % lr.coef_[0])\n",
        "print('Punkt przecięcia: %.3f' % lr.intercept_)\n",
        "\n",
        "plt.scatter(dfx_train[['BMI']], dfy_train, c='lightblue')\n",
        "\n",
        "x_range = [dfx_train[['BMI']].min().values, dfx_train[['BMI']].max().values ]\n",
        "plt.plot(x_range, lr.predict(x_range), color='red', linewidth=2) \n",
        "\n",
        "plt.xlabel('BMI')\n",
        "plt.ylabel('Y')\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "dfy_train_pred = lr.predict(dfx_train[['BMI']])\n",
        "dfy_test_pred = lr.predict(dfx_test[['BMI']])\n",
        "\n",
        "mse_train = mean_squared_error(dfy_train, dfy_train_pred)\n",
        "mse_test  = mean_squared_error(dfy_test, dfy_test_pred)\n",
        "print('MSE na próbkach uczących: %.3f, testowych: %.3f' % (mse_train, mse_test))\n",
        "\n",
        "r2_train = r2_score(dfy_train, dfy_train_pred)\n",
        "r2_test  = r2_score(dfy_test, dfy_test_pred)\n",
        "print('Współczynnik R^2 dla danych uczących: %.3f, testowych: %.3f' % (r2_train, r2_test))\n",
        "\n",
        "res = pd.DataFrame(columns = ['MSE train', 'MSE test', 'R2 train', 'R2 test'])\n",
        "res.loc['LR zmienna [BMI]'] = [mse_train, mse_test, r2_train, r2_test]\n",
        "res\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYOEYAxcQz4h"
      },
      "source": [
        "4. Zbuduj model regresji liniowej wielowymiarowej uwzględniając wszystkie zmienne do opisu zmiennej wyjściowej `Y`. Zastosuj w tym celu jedną, wybraną metodę z regularyacją (np. grzbietową lub Lasso). Przeprowadź obliczenia dla przynajmniej 2 róznych wartości współczynnika określającego siłę regularyzacji $\\alpha$ i porównaj wyniki. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWDacdR2Qz4h"
      },
      "source": [
        "res = pd.DataFrame(columns = ['MSE train', 'MSE test', 'R2 train', 'R2 test'])\n",
        "\n",
        "lasso = Lasso(alpha=0.1)\n",
        "lasso.fit(dfx_train, dfy_train)\n",
        "dfy_train_pred = lasso.predict(dfx_train)\n",
        "dfy_test_pred = lasso.predict(dfx_test)\n",
        "print(lasso.coef_)\n",
        "\n",
        "res.loc['Lasso alpha=0.1 wszystkie zmienne'] = [ mean_squared_error(dfy_train, dfy_train_pred), mean_squared_error(dfy_test, dfy_test_pred), r2_score(dfy_train, dfy_train_pred), r2_score(dfy_test, dfy_test_pred) ]\n",
        "res\n",
        "\n",
        "lasso = Lasso(alpha=0.3)\n",
        "res.loc['Lasso alpha=0.3 wszystkie zmienne'] = [ mean_squared_error(dfy_train, dfy_train_pred), mean_squared_error(dfy_test, dfy_test_pred), r2_score(dfy_train, dfy_train_pred), r2_score(dfy_test, dfy_test_pred) ]\n",
        "res\n",
        "\n",
        "lasso = Lasso(alpha=0.5)\n",
        "res.loc['Lasso alpha=0.5 wszystkie zmienne'] = [ mean_squared_error(dfy_train, dfy_train_pred), mean_squared_error(dfy_test, dfy_test_pred), r2_score(dfy_train, dfy_train_pred), r2_score(dfy_test, dfy_test_pred) ]\n",
        "res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka1VhQ1VQz4h"
      },
      "source": [
        "5. Spośród stworzonych modeli regresji wybierz najlepszy (ten o najmniejszym MSE na zbiorze testowym) i wypisz (lub wyświetl) jego współczynniki regresji."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It7g1CASQz4h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "73c3c1c9-2feb-410c-bbc9-7c4fbf74ab6c"
      },
      "source": [
        "lasso = Lasso(alpha=0.1)\n",
        "res = pd.DataFrame(columns = ['R2 train', 'R2 test'])\n",
        "res.loc['Lasso alpha=0.1 wszystkie zmienne'] = [r2_score(dfy_train, dfy_train_pred), r2_score(dfy_test, dfy_test_pred) ]\n",
        "res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R2 train</th>\n",
              "      <th>R2 test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Lasso alpha=0.1 wszystkie zmienne</th>\n",
              "      <td>0.555354</td>\n",
              "      <td>0.357998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   R2 train   R2 test\n",
              "Lasso alpha=0.1 wszystkie zmienne  0.555354  0.357998"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    }
  ]
}